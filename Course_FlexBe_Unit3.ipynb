{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FlexBe with ROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/flexbe_img.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/robotignite_logo_text.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 3: Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">SUMMARY</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time to completion: <b>2 hours</b><br><br>\n",
    "In this unit, you are going to learn how to create unit tests for your FlexBe states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">END OF SUMMARY</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So at this point, you are already capable of creating complex behaviors in FlexBe, adding many states to it. But there's one more thing I'd like to show you..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unit Testing!** Unit testing of FlexBe states is very helpful for ensuring that the building blocks for your behaviors work as expected. And thankfully, FlexBe provides a tool that will allow you to create unit tests for your states in a very simple and fast way. That tool is called **flexbe_testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**flexbe_testing** is a simple and lightweight framework for unit-testing your states. While composing behaviors out of predefined states in the FlexBE UI helps to avoid errors in composition, flexbe_testing ensures that these predefined states themselves work as expected.\n",
    "\n",
    "Test cases are created as short yaml files and are passed to a launch file for execution. Per convention, each ROS package defining states in its src folder is expected to also have a tests folder containing tests for these states. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next exercise, you will see how to create unit tests for your states. So... let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 3.1**</p>\n",
    "<br>\n",
    "\n",
    "a) First of all, let's create a new folder called **tests** inside our package. In this folder, we will place all the test files we create for our states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roscd turtlebot_flexbe_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Next, let's create our first test file. Inside the **tests** folder, create a new file called **drive_forward_test.test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "touch drive_forward_test.test;chmod +x drive_forward_test.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can copy the following contents into the file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**drive_forward_test.test**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path: turtlebot_flexbe_states.go_forward_state\n",
    "class: GoFowardState\n",
    "\n",
    "params:\n",
    "    speed: 0.4\n",
    "    travel_dist: 1\n",
    "    obstacle_dist: 1.5\n",
    "\n",
    "outcome: failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**drive_forward_test.test**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In order to execute the test, you just need to run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roslaunch flexbe_testing flexbe_testing.launch testcases:='$(find turtlebot_flexbe_states)/tests/drive_forward_test.test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything goes OK, you should see your test pass successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/flexbe_test_ok.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">**¡¡VERY IMPORTANT!!** Remember that, whenever you are done with the Exercise, you can reset the robot's position by hitting on the button **Reset the simulation!**, at the top-right corner of the simulation screen.</span>\n",
    "\n",
    "<img src=\"img/reset_sim.png\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**End of Exercise 3.1**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... what have you just done? Let's try to explain it. And for that, let's try to analyze the test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path: turtlebot_flexbe_states.go_forward_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **path** parameter indicates the Python import path of the state we want to test. It should only point to states of the same package when placed inside a state package. In this case, the state we want to test is in the **turtlebot_flexbe_states** package, and its file name is **go_forward_state.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class: GoFowardState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **class** parameter indicates the name of the Python class of the state to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params:\n",
    "    speed: 0.4\n",
    "    travel_dist: 1\n",
    "    obstacle_dist: 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **params** parameter, as you can see, provides a list of key-value pairs of all the parameters defined by the state to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome: failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the **outcome** parameters indicate the outcome to be expected by the state. In this case, we know that the robot is going to stop because it's going to find an obstacle in it's way, causing the outcome of the state to be **failed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other parameters that you can use in your test files, though. Below you can see a complete list of all of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **path **(required): Python import path of the state to be tested. Should only point to states of the same package when placed inside a state package.\n",
    "\n",
    "* **class** (required): Python class name of the state to be tested.\n",
    "\n",
    "* **import_only** (optional): Is false per default and only needs to be declared when set to true. Will just import the declared state and not execute it. Importing a state can find a lot of possible errors, without running the whole system.\n",
    "\n",
    "* **launch** (optional): Launch file that should be executed in parallel to running the tests. Can either reference an existing launchfile or define one in-place.\n",
    "\n",
    "* **data** (optional): Bag file used as data source for message-based data. Can be used for params, input, and output values, as explained in the next section.\n",
    "\n",
    "* **params**: Parameters given as key value pairs for all parameters defined by the state.\n",
    "\n",
    "* **input**: Input userdata given as key value pairs for all input keys defined by the state.\n",
    "\n",
    "* **output**: Output userdata given as key value pairs for all output keys defined by the state. The values of this data will be compared to the values returned by the state after execution. A test can only succeed if all values match.\n",
    "\n",
    "* **outcome** (required): One of the outcomes as defined by the state. This outcome is expected to be returned in the end and the test can only succeed if this outcome matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, though, your test cases will require external nodes to be running, as a state primarily interfaces external functionality. But this is no problem, since you can simply launch all the components you need automatically, and then run the tests. For instance, we have an example case in our Actionlib state, since we need to run our Action Server before being able to use our state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's create a unit test for our Actionlib state in the following exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 3.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Let's create another test file for the Actioblib state. Inside the **tests** folder, create a new file called **turn_test.test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roscd turtlebot_flexbe_states/tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "touch turn_test.test;chmod +x turn_test.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Complete the test file, following what you've learned in the previous exercise. In order to launch the Action Server, you can use the **launch** parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) You will need to also generate a launch file that starts the Action Server, in case you don't have one yet. It could be something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**spin_server.launch**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<launch>\n",
    "    <node pkg=\"spin_action_server\" type=\"spin_server.py\" name=\"spin_node\" output=\"screen\" />\n",
    "</launch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**spin_server.launch**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Finally, let's execute the test. You just need to run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roslaunch flexbe_testing flexbe_testing.launch testcases:='$(find turtlebot_flexbe_states)/tests/turn_test.test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything goes OK, you should see your test pass successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/flexbe_test_ok.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**End of Exercise 3.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:red;color:white;\">**Solution Exercise 3.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**turn_test.test**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path: turtlebot_flexbe_states.go_forward_state\n",
    "class: GoFowardState\n",
    "    \n",
    "launch: spin_action_server/launch/spin_server.launch\n",
    "\n",
    "params:\n",
    "    speed: 0.4\n",
    "    travel_dist: 1\n",
    "    obstacle_dist: 1.5\n",
    "\n",
    "outcome: done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**turn_test.test**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:red;color:white;\">**END Solution Exercise 3.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, the extent to which you write test cases depends on the target use case. However, there are a few guidelines when developing states that are made publicly available. Also, for your own project, it might be advantageous to stick to these, especially when you intend to release them eventually.\n",
    "\n",
    "**Import Only**: Every state should have an import-only test. There is absolutely no reason why not. Such a test definition consists of three lines and does not require any test data or runtime setup. It helps to detect a lot of errors, such as missing imports, inconsistent indentation, or syntax typos. Practically speaking, this is similar to checking for compilation errors in C++ code. You only need the import-only test if there is no other test for this state (since import is part of all tests).\n",
    "\n",
    "**Simple Examples**: In most cases, a test case with simple and intended values out of the defined/documented input space should be feasible with reasonable effort, and is beneficial to making sure that at least what is intended happens when provided with what is expected. Optimally, there is one example for each equivalence class of the input space.\n",
    "\n",
    "**Negative Examples**: Similar to test cases based on data of the defined input space, this class of tests is intended to make sure that the state can also handle erroneous input data without crashing, or unexpected behavior. This prevents runtime errors from spreading across multiple states by passing unexpected data. However, negative examples are primarily required for rather critical systems.\n",
    "\n",
    "**Advanced Scenarios**: If reasonable for certain states, well-defined scenarios help to run more realistic test cases. These tests typically require a bunch of recorded messages and external ROS nodes, and are mostly project-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Congratulations!! You are now capable of creating Unit Tests for your FlexBe states!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
