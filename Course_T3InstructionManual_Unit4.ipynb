{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering with ROS: Turtlebot3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/robotis_logo.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/blob_unit.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/robotignite_logo_text.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 4: Blob Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">SUMMARY</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time of completion: **2h**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this unit, you will start using cameras in ROS and use the cmvision package for blob tracking. Once you get the hang of it, then in Unit 2, you will go deeper in how this blob tracking is done and how the image can be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">END OF SUMMARY</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you are going to see what the robot Turtlebot3 is seeing. For that, you are going to use a ROS graphical tool called <i>rqt_image_view</i> that allows you to see what the camera in the robot is publishing.\n",
    "\n",
    "To open the tool, type the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #2</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rosrun rqt_image_view rqt_image_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, open the Graphical Display by clicking on the icon:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "Graphical Tool Icon",
    "image": true,
    "name": "font-awesome_desktop",
    "width": "1.3cm"
   },
   "source": [
    "<img src=\"img/font-awesome_desktop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you should see on the screen a window of the **rqt_image_view** application.\n",
    " \n",
    "On the application, select the **/camera/rgb/image_raw** image topic and wait a few seconds until the image feed is established. You should see something similar to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "Camera Vision",
    "image": true,
    "name": "perception_Unit1_miravision",
    "width": "10cm"
   },
   "source": [
    "<img src=\"img/rqt_image.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 4.1**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now get move Turtlebot3 around until the red ball appears in the robot's view. Once it is in view of the Turtlebot3 robot, you can close the program of WebShell #2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**END Exercise 4.1**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob tracking with OpenCV and Python  part 1, color encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what you are going to do is create a program that can track blobs of colour in an image.<br>\n",
    "Blobs are nothing more than areas in an image with a similar color encoding, as similar as you might define it.<br>\n",
    "So, obviously, the first step is to get a color encoding that defines the object you want to be tracked.<br>\n",
    "Let's do that with the red ball, shall we?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the color encoding, we are going to use another tool provided by ROS that allows to easily compute the RBG and YUV values of a target blob.\n",
    " \n",
    "Launch the following command in a terminal and go to the Graphical Interface Tab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #2</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roslaunch blob_tracking_t3 start_colour_gui.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start a gui similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/color_gui_unfocus.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzoom the image a little bit in order to be able to visualize the ball."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "Colour Gui",
    "image": true,
    "name": "perception_unit1_colourset2",
    "width": "10cm"
   },
   "source": [
    "<img src=\"img/color_gui1.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, click over the red ball and see how by successively clicking over slightly different points of the ball, a black box appears around it. Click over it until the box is just over the entire red ball:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "Colour Gui all red ball detected",
    "image": true,
    "name": "perception_unit1_colourset3",
    "width": "10cm"
   },
   "source": [
    "<img src=\"img/color_gui2.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the two text boxes? You have the RGB value of the color on average and then you have the YUV, which, in this case, is **(30:82, 86:111, 178:252)**. Yours could be slightly different. But, the point is that this YUV defines the color blob to be tracked. This means that this is what Turtlebot3 will consider to be the RedBall.\n",
    "\n",
    "You can now close the WebShell #2 program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to use those values to create a configuration file, required by the blob recognition code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a package to launch all of the required software to track the ball.\n",
    "\n",
    "* First, create a new package named <i>my_blob_tracking_pkg</i>, which depends on <i>rospy</i>.\n",
    "* Inside that package, create a directory named <i>color_files</i> and put the <i>colors.txt</i> file in it. Add the values you got in the previous step, by writing the RGB in average and the YUV values like in the file below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**colors.txt**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[Colors]\n",
    "(  0, 255,  0) 0.000000 10 Green\n",
    "(  0,  0, 255) 0.000000 10 Blue\n",
    "(  255,  255, 0) 0.000000 10 Yellow\n",
    "(  255,  0, 255) 0.000000 10 Purple\n",
    "(  0,  255, 255) 0.000000 10 Teal\n",
    "(  254,  4,   4) 0.000000 10 RedBall\n",
    "\n",
    "[Thresholds]\n",
    "( 144:154, 38:48, 16:26 )\n",
    "( 24:34, 250:255, 102:112 )\n",
    "( 220:230, 0:5, 143:153 )\n",
    "( 100:110, 207:217, 229:239)\n",
    "( 173:183, 165:175, 0:5 )\n",
    "( 30:81, 86:111, 178:253 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**END colors.txt**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that there are two parts: **Colors** and **Thresholds**<br>\n",
    "In **Colors**, you state:<br>\n",
    "\n",
    "* The RGB value of the line around the detection, in this case, is the same color as the average RGB color detected previously, but you can put any color you want. It's just good practice to put the Average color because, that way, you can see what blob is being detected.\n",
    "* The other two numbers are not used in this version of cmvision.\n",
    "* The name of the blob representation, in this case RedBall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **Thresholds**, you state:<br>\n",
    "\n",
    "* Essentially, the Red, Green, and Blue value range. In the case of the RedBall, Red = [from 30 to 81], Green = [from 86 to 111], and Blue = [from 178 to 253]\n",
    "* All of them are placed in the same order as the Color List to make the correspondence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you can put as many colors as you wish and, afterwards, be able to track different blobs based on their names, like Green, RedBall, Teal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob tracking with OpenCV and Python part 2, Start blob tracking with cmvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROS package that you have used for the color setting and that you will use for the tracking is **cmvision**, http://wiki.ros.org/cmvision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following launch file that starts the blob tracking code based on your <i>colour.txt</i> file, connect to Turtlebot3's camera, and publish the ball position and information in a ROS topic. You must add this launch file to the launch directory of your package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**my_t3_cmvision_tc.launch**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<launch>\n",
    "  \n",
    "  <arg name=\"rgb_raw_image_topic\" default=\"/camera/rgb/image_raw\"/>\n",
    "  <arg name=\"color_file_path\" default=\"$(find my_blob_tracking_pkg)/color_files/colors.txt\"/>\n",
    "  \n",
    "  <!-- Location of the cmvision color file -->\n",
    "  <param name=\"cmvision/color_file\" type=\"string\" \n",
    "         value=\"$(arg color_file_path)\" />\n",
    "\n",
    "  <!-- Turn debug output on or off -->\n",
    "  <param name=\"cmvision/debug_on\" type=\"bool\" value=\"true\"/>\n",
    "\n",
    "  <!-- Turn color calibration on or off -->\n",
    "  <param name=\"cmvision/color_cal_on\" type=\"bool\" value=\"false\"/>\n",
    "\n",
    "  <!-- Enable Mean shift filtering -->\n",
    "  <param name=\"cmvision/mean_shift_on\" type=\"bool\" value=\"false\"/>\n",
    "\n",
    "  <!-- Spatial bandwidth: Bigger = smoother image -->\n",
    "  <param name=\"cmvision/spatial_radius_pix\" type=\"double\" value=\"2.0\"/>\n",
    "\n",
    "  <!-- Color bandwidth: Bigger = smoother image-->\n",
    "  <param name=\"cmvision/color_radius_pix\" type=\"double\" value=\"40.0\"/>\n",
    "\n",
    "  <node name=\"cmvision\" pkg=\"cmvision\" type=\"cmvision\" args=\"image:=$(arg rgb_raw_image_topic)\" \n",
    "        output=\"screen\" />\n",
    "</launch>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**END my_t3_cmvision_tc.launch**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you set the image topic from which the RGB data will be extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<arg name=\"rgb_raw_image_topic\" default=\"/camera/rgb/image_raw\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you set the path to the color file you created through the given path or, if not, the default value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<arg name=\"color_file_path\" default=\"$(find my_blob_tracking_pkg)/color_files/colors.txt\"/>\n",
    "<!-- Location of the cmvision color file -->\n",
    "  <param name=\"cmvision/color_file\" type=\"string\" \n",
    "         value=\"$(arg color_file_path)\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you launch the cmvision node that will make the blob tracking happen based on the image topic given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<node name=\"cmvision\" pkg=\"cmvision\" type=\"cmvision\" args=\"image:=$(arg rgb_raw_image_topic)\" \n",
    "        output=\"screen\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other parameters are irrelevant for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roslaunch my_blob_tracking_pkg my_t3_cmvision_tc.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If you see the error <i>libdc1394 error: Failed to initialize libdc1394</i> do not worry. Everything is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should, then, have blob information published in the <i>/blobs</i> topic. Let's check what is published in that topic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #2</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rostopic list | grep /blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should show the topic <i>/blobs</i> on the screen.\n",
    "\n",
    "Now, let's check some info about the topic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #2</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rostopic info /blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will give you the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user ~ $ rostopic info /blobs            \n",
    "Type: cmvision/Blobs                      \n",
    "Publishers:                              \n",
    " * /cmvision (http://ip-172-31-36-185:42984/)\n",
    "Subscribers: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analize the message obtained through that topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user ~ $ rosmsg show cmvision/Blobs                                   \n",
    "std_msgs/Header header                                    \n",
    "  uint32 seq                                    \n",
    "  time stamp                                    \n",
    "  string frame_id                                   \n",
    "uint32 image_width                                    \n",
    "uint32 image_height                                   \n",
    "uint32 blob_count                                   \n",
    "cmvision/Blob[] blobs                                   \n",
    "  string name                                   \n",
    "  uint32 red                                    \n",
    "  uint32 green                                    \n",
    "  uint32 blue                                   \n",
    "  uint32 area                                   \n",
    "  uint32 x                                    \n",
    "  uint32 y                                    \n",
    "  uint32 left                                   \n",
    "  uint32 right                                    \n",
    "  uint32 top                                    \n",
    "  uint32 bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the <i>Blobs</i> message is an array of <i>cmVision/blob</i> messages.\n",
    "\n",
    "So, what is in a <i>cmVision/blob</i> message?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user ~ $ rosmsg show cmvision/Blob                                    \n",
    "string name                                   \n",
    "uint32 red                                    \n",
    "uint32 green                                    \n",
    "uint32 blue                                   \n",
    "uint32 area                                   \n",
    "uint32 x                                    \n",
    "uint32 y                                    \n",
    "uint32 left                                   \n",
    "uint32 right                                    \n",
    "uint32 top                                    \n",
    "uint32 bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each <i>cmVision/blob</i> message provides the information for a single detected blob.\n",
    "\n",
    "As you can see, you will get a lot of information out of each detected blob. Although the most important information is the blob name, the position in the image, and the size. With this, you can position the blob in a 2D, and maybe in a 3D, space and know which blob it is, able to track multiple objects in 3D space, if they are sufficiently different in colour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you should see the Turtlebot3 camera with the tracking in the Graphical Interface already working. If you don't have a red box around the ball, you should check that the YUV you gave are enough, and run the color setup again, if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "Blob tracking of red ball",
    "image": true,
    "name": "perception_unit1_cmvisiontrack1",
    "width": "10cm"
   },
   "source": [
    "<img src=\"img/perception_unit1_cmvisiontrack1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 4.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a python script that retrieves the needed information from the /blob topic to be able to:<br>\n",
    "\n",
    "* Filter all the blobs, except the RedBall blobs\n",
    "* Retrieve its position in 2D in the image\n",
    "* Make Turtlebot3 move so that the red ball is in the center of the image all the time. \n",
    "* Move the ball using the keyboard and really check that the robot is moving to always keep the red ball in the middle of the screen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/blob_tracking.gif\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to move the ball with the keyboard, you can use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roslaunch blob_tracking move_ball_keyboard.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**END Exercise 4.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">**Solution Exercise 4.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please try to do it by yourself unless you get stuck or need some inspiration. You will learn much more if you fight for each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "RobotIgnite",
    "image": true,
    "name": "robotignite_logo_text",
    "width": "10cm"
   },
   "source": [
    "<img src=\"img/robotignite_logo_text.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you have an example of how it could be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import rospy\n",
    "from geometry_msgs.msg import Twist\n",
    "from cmvision.msg import Blobs, Blob\n",
    "\n",
    "#global\n",
    "turn = 0.0 #turning rate\n",
    "blob_position = 0 # x position for the blob\n",
    "\n",
    "# callback function checks to see if any blobs were found then\n",
    "# loop through each and get the x position.  Since the camera\n",
    "# will sometimes find many blobs in the same object we just\n",
    "# average all the x values.  You could also just take the first\n",
    "# one if you are sure you will only have one blob. \n",
    "#\n",
    "# This doesn't use multiple blobs but if are tracking several \n",
    "# objects you need to check the /data.blobs.color topic for\n",
    "# the color tag you put in your colors.txt file. \n",
    "#\n",
    "# after we have the x value we just make the robot turn to \n",
    "# keep it in the center of the image.\n",
    "\n",
    "def callback(data):\n",
    "    global turn\n",
    "    global blob_position\n",
    "\n",
    "    if(len(data.blobs)):\n",
    "\n",
    "        for obj in data.blobs:\n",
    "            if obj.name == \"RedBall\":\n",
    "                rospy.loginfo(\"Blob <\"+str(obj.name)+\"> Detected!\")\n",
    "                blob_position = obj.x\n",
    "        \n",
    "                rospy.loginfo(\"blob is at %s\"%blob_position)\n",
    "                # turn right if we set off the left cliff sensor\n",
    "                if( blob_position > 1000 ):\n",
    "                    rospy.loginfo(\"TURN RIGHT\")\n",
    "                    turn = -1.0\n",
    "                # turn left if we set off the right cliff sensor\n",
    "                if( blob_position < 900 ):\n",
    "                    rospy.loginfo(\"TURN LEFT\")\n",
    "                    turn = 1.0\n",
    "        \n",
    "                if( blob_position > 900 and blob_position < 1000):\n",
    "                    rospy.loginfo(\"CENTERED\")\n",
    "                    turn = 0.0\n",
    "    else: \n",
    "        turn = 0.0\n",
    "\n",
    "def run():\n",
    "    rospy.init_node(\"track_blob_color_node\", log_level=rospy.WARN)\n",
    "    global blob_position\n",
    "    # publish twist messages to /cmd_vel\n",
    "    pub = rospy.Publisher('/cmd_vel', Twist, queue_size=1)\n",
    "\n",
    "    #subscribe to the robot sensor state\n",
    "    rospy.Subscriber('/blobs', Blobs, callback)\n",
    "    \n",
    "\n",
    "    global turn\n",
    "    twist = Twist()\n",
    "\n",
    "    while not rospy.is_shutdown():\n",
    "\n",
    "        # turn if we hit the line\n",
    "        if ( turn != 0.0 ):\n",
    "            str = \"Turning %s\"%turn\n",
    "            rospy.loginfo(str)\n",
    "            twist.linear.x = 0.0; twist.linear.y = 0; twist.linear.z = 0\n",
    "            twist.angular.x = 0; twist.angular.y = 0; twist.angular.z = turn\n",
    "            turn = 0.0\n",
    "\n",
    "            # straight otherwise\n",
    "        else:\n",
    "            str = \"Straight %s\"%turn\n",
    "            rospy.loginfo(str)\n",
    "            twist.linear.x = 0.0; twist.linear.y = 0; twist.linear.z = 0\n",
    "            twist.angular.x = 0; twist.angular.y = 0; twist.angular.z = 0\n",
    "\n",
    "            # send the message and delay\n",
    "        pub.publish(twist)\n",
    "        blob_position = 0\n",
    "        rospy.sleep(0.1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        run()\n",
    "    except rospy.ROSInterruptException: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You can now track anything with color. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_metadata": {
   "chapter": "1 - Vision Basics in ROS Part 1, Follow a Red Ball",
   "chapter_title": "Unit 1: Vision Basics in ROS Part 1, Follow a Red Ball",
   "course_title": "ROS PERCEPTION IN 5 DAYS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
