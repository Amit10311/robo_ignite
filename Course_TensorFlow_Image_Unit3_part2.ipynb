{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 part2: Train your Own TensorFlow Image Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tensorflow_image_unit3_label1_results1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/robotignite_logo_text.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Estimated time to completion:</b> 2.5-10 hours, depending on the training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Simulated robot:</b> Mira Robot\n",
    "<br><br>\n",
    "<b>What will you learn with this unit?</b>\n",
    "* Use the trained model in a ROS environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#AB0017;color:white;\">**WARNING**</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second part needs the Part1 for it to work, so don't do it until Part1 is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#AB0017;color:white;\">**END WARNING**</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Launch the Testing Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here comes the **ROS** connection again. So, what we want is for our robot, Mira, to recognise itself in the virtual world. And perhaps in the **real world**. So, we have to make recognitions in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10.1: Create the Python script that combines TensorFlow with ROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a combination of the **test_training.py** and the **image_recognition.py** from **Unit 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#3B8F10;color:white;\" id=\"import_pb_to_tensorboard\">**Python Program {3.5-py}: search_for_mira_robot.py** </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "#from matplotlib import pyplot as plt\n",
    "#from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import rospkg\n",
    "import rospy\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "  \n",
    "# get an instance of RosPack with the default search paths\n",
    "rospack = rospkg.RosPack()\n",
    "# get the file path for rospy_tutorials\n",
    "\n",
    "path_to_learn_pkg = rospack.get_path('learn_newobjects_tf_pkg')\n",
    "research_module_path = os.path.join(path_to_learn_pkg,\"scripts/models/research\")\n",
    "object_detection_module_path = os.path.join(path_to_learn_pkg,\"scripts/models/research/object_detection\")\n",
    "sys.path.append(object_detection_module_path)\n",
    "\n",
    "#print(sys.path)\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "# What model to download.\n",
    "MODEL_NAME = 'learned_model'\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "scripts_module_path = os.path.join(path_to_learn_pkg,\"scripts/\")\n",
    "final_path_to_ckpt = os.path.join(scripts_module_path,PATH_TO_CKPT)\n",
    "\n",
    "# List of the strings that is used to add correct label for each box. In our case mira_robot\n",
    "PATH_TO_LABELS = os.path.join(scripts_module_path, 'training/object-detection.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(final_path_to_ckpt, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "      \n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for a single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframing is required to translate the mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict\n",
    "  \n",
    "\n",
    "class RosTensorFlow():\n",
    "    def __init__(self):\n",
    "        # Processing the variable to process only half of the frame's lower load\n",
    "        self._process_this_frame = True\n",
    "        self._cv_bridge = CvBridge()\n",
    "\n",
    "        self._sub = rospy.Subscriber('image', Image, self.callback, queue_size=1)\n",
    "        self._pub = rospy.Publisher('result', String, queue_size=1)\n",
    "        self.score_threshold = rospy.get_param('~score_threshold', 0.1)\n",
    "        self.use_top_k = rospy.get_param('~use_top_k', 5)\n",
    "        \n",
    "        \n",
    "\n",
    "    def callback(self, image_msg):\n",
    "        if (self._process_this_frame):\n",
    "            \n",
    "            image_np = self._cv_bridge.imgmsg_to_cv2(image_msg, \"bgr8\")\n",
    "    \n",
    "            # Expand dimensions since the model expects images to have shapes: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            # Actual detection.\n",
    "            output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                output_dict['detection_boxes'],\n",
    "                output_dict['detection_classes'],\n",
    "                output_dict['detection_scores'],\n",
    "                category_index,\n",
    "                instance_masks=output_dict.get('detection_masks'),\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=8)\n",
    "            cv2.imshow(\"Image window\", image_np)\n",
    "            cv2.waitKey(1)\n",
    "        else:\n",
    "            pass\n",
    "        # We invert it\n",
    "        self._process_this_frame = not self._process_this_frame\n",
    "        \n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        rospy.spin()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rospy.init_node('search_mira_robot_node')\n",
    "    tensor = RosTensorFlow()\n",
    "    tensor.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#3B8F10;color:white;\" id=\"import_pb_to_tensorboard\">**END Python Program {3.5-py}: search_for_mira_robot.py** </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10.2: Create the launch file for starting the SearchFor MiraRobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just create the launch file in exactly the same way as you did in Unit 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#3B8F10;color:white;\" id=\"start_image_recognition\">**Launch File {3.6-launch}: start_search_mira_robot.launch** </p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "\n",
    "<launch> \n",
    "    <arg name=\"rgb_image_topic\" default=\"/mira/mira/camera1/image_raw\" />\n",
    "    \n",
    "    <node \n",
    "    name=\"search_for_mira_robot_node\"\n",
    "    pkg=\"tf_unit1_pkg\"\n",
    "    type=\"search_for_mira_robot.py\"\n",
    "    args=\"\"\n",
    "    output=\"screen\">\n",
    "    \n",
    "    <remap from=\"image\" to=\"$(arg rgb_image_topic)\" />\n",
    "    \n",
    "    </node>\n",
    "    \n",
    "</launch> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#3B8F10;color:white;\" id=\"start_image_recognition\">**END Launch File {3.6-launch}: start_search_mira_robot.launch** </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, you launch it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:left;background: #407EAF\">\n",
    "<tr>\n",
    "<th>\n",
    "<p class=\"transparent\">Execute in WebShell #1</p>\n",
    "</th>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Launch the Testing for Mira in the learn_newobjects_tf_pkg main.launch world\n",
    "roslaunch tf_unit1_pkg start_search_mira_robot.launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have to go to the **Graphical Tools**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/font-awesome_desktop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tensorflow_image_unit3_label1_results1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tensorflow_image_unit3_label1_results2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions of Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably have seen that teaching this model only **ONE** thing has led to making it an **object** recogniser, rather than  having the ability to differentiate between **mira_robot** and **everything else**.<br>\n",
    "So, that's the next step that **you will have to do** in the following exercise, **3.2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#407EAF;color:white;\">END **Example 3.1**</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**Exercise 3.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now you have to make Mira Robot **differentiate** between **mira_robots** and **other objects**.<br>\n",
    "This means that you will have to train with **TWO** labels. Therefore, you will have to make all of the necessary modifications so that it trains with the label **mira_robot** and the label **object**.<br>\n",
    "* To make this task less painful, we have already provided a folder with all of the images labeled with two tags. You can find them in the public git **course_tflow_image_student_data/images_2_labels**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#EE9023;color:white;\">**END Exercise 3.2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">Solution Exercise 3.2</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please try to do it by yourself, unless you get stuck or need some inspiration. You will learn much more if you fight for each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/robotignite_logo_text.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this link to open the solutions notebook for Unit 3:[solutions_tensofrflow_images_unit3](extra_files/solutions_tensofrflow_images_unit3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning process should look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tensorflow_image_unit3_15hourslearning_labels2.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a learning process of more than 15 hours. But, as you can see, after about the 8th hour, there is no significant improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your detection process should look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/tensorflow_image_unit3_ex3-2_solution.gif\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:green;color:white;\">END Solution Exercise 3.2</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
