{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#be2d24\">OpenAI Gym in Gazebo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#be2d24\">About OpenAI Gym and this simulation</span>\n",
    "\n",
    "[<img align=\"right\" src=\"img/logo/openai.png\" style=\"width:324px;height:118px;\" />](https://openai.com)\n",
    "\n",
    "In this course, you are going to learn about using OpenAI Gym and Gazebo, and using a language called [Python](https://www.python.org).\n",
    "\n",
    "OpenAI is a non-profit, artificial intelligence (AI) research company that aims to \"freely collaborate\" with other institutions and researchers by making its patents and research open to the public. It has been established with a focus on creating AI that has a positive human impact. \n",
    "\n",
    "In April 2016, OpenAI introduced \"Gym,\" a platform for developing and comparing reinforcement learning algorithms. Reinforcement learning is an area of machine learning that allows an intelligent agent (for example, a robot) to learn the best behaviors in an environment by trial-and-error. The agent takes action in an environment so as to maximize its rewards. It is similar to teaching a dog a new trick: reward it if it does the right thing or punish it if it does the wrong thing. The dog eventually learns to behave well so that it keeps getting the rewards.\n",
    "\n",
    "In this example, we will be seeing how a turtlebot is able to learn navigation through an environment without hitting an obstacle. The turtlebot will use a reinforcement learning method known as Q-learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#be2d24;\">Running the simulation</span>\n",
    "\n",
    "There are four environments already available with which the user can test their simulations. These environments can be launched using the respective launch files:\n",
    "\n",
    "- GazeboCircuitTurtlebotLidar_v0.launch:    \n",
    "- GazeboCircuit2TurtlebotLidar_v0.launch:\n",
    "- GazeboRoundTurtlebotLidar_v0.launch:\n",
    "- GazeboMazeTurtlebotLidar_v0.launch:\n",
    "\n",
    "<table>\n",
    "<caption>The various environments already available:</caption>\n",
    "<colgroup>\n",
    "<col width=\"20%\" />\n",
    "<col width=\"20%\" />\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td align=\"right\">Circuit<br><img src=\"img/env/circuit.png\" style=\"width:124px;height:218px;\" alt=\"\" /></td>\n",
    "<td align=\"left\">Circuit2<br><img src=\"img/env/circuit2.png\" style=\"width:124px;height:218px;\" alt=\"\" /></td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td align=\"right\">Round<br><img src=\"img/env/round.png\" style=\"width:124px;height:218px;\" alt=\"\" /></td>\n",
    "<td align=\"left\">Maze<br><img src=\"img/env/maze.png\" style=\"width:124px;height:218px;\" alt=\"\" /></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "It is requested that the user try out the existing environment before developing their own environments for training the robot. An environment is where the robot's possible actions and rewards are defined. For example, in the available environments, there are three possible actions for the Turtlebot robot:\n",
    "\n",
    "- Forward (with a reward of 5 points)\n",
    "- Left (with a reward of 1 point)\n",
    "- Right (with a reward of 1 point)\n",
    "\n",
    "If it collides with the walls, then the training episode ends (with a penalty of 200 points). The turtlebot has to learn to navigate through the environment, based on the rewards obtained from different episodes. This can be achieved using the Q-learning algorithm. Let's see how it works.\n",
    "\n",
    "First, we have to set the path, as given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python2.7/dist-packages/\")\n",
    "sys.path.append(\"/home/ubuntu/gym-gazebo\")\n",
    "sys.path.append(\"/home/user/catkin_ws/src/gym_construct/src\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python scripts in the `gym_construct/src/` folder (listed below) help us simulate the reinforcement learning techniques for a Turtlebot. Currently, the number of episodes has been set to 20.\n",
    "Feel free to increase the number of episodes in the python scripts (upto 5000) to actually train the robot to navigate the environment completely.\n",
    "\n",
    "Only uncomment the script corresponding to the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'/home/user/catkin_ws/src/gym_construct/src/round_turtlebot_lidar_test.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "## Circuit-1 Environment --> Q-learning\n",
    "#%run /home/user/catkin_ws/src/gym_construct/src/circuit_turtlebot_lidar_qlearn.py\n",
    "\n",
    "## Circuit-2 Environment --> Q-learning\n",
    "#%run /home/user/catkin_ws/src/gym_construct/src/circuit2_turtlebot_lidar_qlearn.py\n",
    "\n",
    "## Circuit-2 Environment --> SARSA\n",
    "#%run /home/user/catkin_ws/src/gym_construct/src/circuit2_turtlebot_lidar_sarsa.py\n",
    "\n",
    "## Round Environment --> Q-learning\n",
    "%run /home/user/catkin_ws/src/gym_construct/src/round_turtlebot_lidar_test.py\n",
    "\n",
    "## Maze Environment --> Q-learning\n",
    "#%run /home/user/catkin_ws/src/gym_construct/src/maze_turtlebot_lidar_qlearn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>There were ouput files produced in the last step and the ROS environment has changed. Therefore, at this point, restart the kernel. <p><img align=\"left\" src=\"img/env/restart.png\"/></p> </div>\n",
    "\n",
    "<br/>\n",
    "<p>Then, set up the path again, as shown below.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/lib/python2.7/dist-packages/\")\n",
    "sys.path.append(\"/home/ubuntu/gym-gazebo\")\n",
    "sys.path.append(\"/home/user/catkin_ws/src/gym_construct/src\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%run /home/user/catkin_ws/src/gym_construct/src/display_plot.py\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#be2d24\">Define your own environment for training the robot!</span>\n",
    "<div>\n",
    "<p>It is possible to define your own environment with the robot's actions and rewards. </p>\n",
    "<p>All you have to do is edit the sample environment `gazebo_myenv_turtlebot_lidar.py` in the `gym-myenv` folder and add it to the path. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/user/catkin_ws/src/gym-myenv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the python script in the `gym_construct/src/` that loads the environment `GazeboMyenvTurtlebotLidar_v0` has\n",
    "```\n",
    "import gym_myenv\n",
    "```\n",
    "\n",
    "And then, run the python script.\n",
    "\n",
    "```\n",
    "## Myenv Environment --> Q-learning\n",
    "%run /home/user/catkin_ws/src/gym_construct/src/myenv_turtlebot_lidar_qlearn.py\n",
    "``` \n",
    "That's all. Now it's up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <span style=\"color:#be2d24\">Credits</span>\n",
    "\n",
    "Simulation - gazebo_gym (http://wiki.ros.org/kobuki_gazebo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
